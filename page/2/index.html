<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Shriman Keshri</title>
<meta name=description content><meta name=author content="Shriman Keshri"><link rel=canonical href=https://shrimansoft.github.io/knowledge-base/><link crossorigin=anonymous href=https://shrimansoft.github.io/knowledge-base/assets/css/stylesheet.min.49b1c3611e5e823e974d0b9b3e1101617fce26c004757161abb1a1e4af3ff85c.css integrity="sha256-SbHDYR5egj6XTQubPhEBYX/OJsAEdXFhq7Gh5K8/+Fw=" rel="preload stylesheet" as=style><link rel=icon href=https://shrimansoft.github.io/knowledge-base/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://shrimansoft.github.io/knowledge-base/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://shrimansoft.github.io/knowledge-base/favicon-32x32.png><link rel=apple-touch-icon href=https://shrimansoft.github.io/knowledge-base/apple-touch-icon.png><link rel=mask-icon href=https://shrimansoft.github.io/knowledge-base/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.123.3"><link rel=alternate type=application/rss+xml href=https://shrimansoft.github.io/knowledge-base/index.xml><link rel=alternate type=application/json href=https://shrimansoft.github.io/knowledge-base/index.json><link rel=alternate hreflang=en href=https://shrimansoft.github.io/knowledge-base/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Shriman Keshri"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://shrimansoft.github.io/knowledge-base/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Shriman Keshri"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Shriman Keshri","url":"https://shrimansoft.github.io/knowledge-base/","description":"","thumbnailUrl":"https://shrimansoft.github.io/knowledge-base/favicon.ico","sameAs":["https://github.com/shrimansoft","https://twitter.com/shrimansoft"]}</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-00000XXXXX"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),-gtag("config","G-00000XXXXX")</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://shrimansoft.github.io/knowledge-base/ accesskey=h title="Shriman Keshri (Alt + H)">Shriman Keshri</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></span></div><ul id=menu><li><a href=https://shrimansoft.github.io/knowledge-base/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://shrimansoft.github.io/knowledge-base/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://shrimansoft.github.io/knowledge-base/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://shrimansoft.github.io/knowledge-base/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2>Important ideas</h2></header><section class=entry-content><p>Reinforcement Learning
Consciousness
Modularity
Causal inference
Evolution
Ability to use tool
Language ( giving identity to our feelings)
randomness
sub-representation
Reprasentation
learning
Images of Important Ideas tools
RL
randomness
Exact sequencec
attention
action = observation
Circle of time
World view
Different feeling
Randomness/ Predictability.
Time
Space
Separation/ Identity
Intelligence/ consciousness.
Drive ( unmoved mover)
Creativity.
Free will
How log is this present?
How past -> future?
where is action action min comes from?...</p></section><footer class=entry-footer><span title='2023-12-02 00:00:00 +0000 UTC'>December 2, 2023</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Shriman Keshri</footer><a class=entry-link aria-label="post link to Important ideas" href=https://shrimansoft.github.io/knowledge-base/pages/important-ideas/></a></article><article class=post-entry><header class=entry-header><h2>Information processing system</h2></header><section class=entry-content><p>The concept of Information processing system( IOP) I read in the book Superrecursive algorithms.
Def: Something that process information, I will have input, output and Processing unit. Although in the book they assumed the triadic structure of IOP. While in my writing I don’t always assume that.
While I am working on the equality between action (output) and observation (input), sticking on the triad structure of IPS can lead to Inadequate results....</p></section><footer class=entry-footer><span title='2023-12-02 00:00:00 +0000 UTC'>December 2, 2023</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Shriman Keshri</footer><a class=entry-link aria-label="post link to Information processing system" href=https://shrimansoft.github.io/knowledge-base/pages/information-processing-system/></a></article><article class=post-entry><header class=entry-header><h2>Local-global</h2></header><section class=entry-content><p>Examples. Global $\to$ Local : ( You want to achieve ____ what should I do now? )
Ex. Lagrangian Machanics $\to$ equation of motions ( Calculus of variations)
Ex. Reward function $\to$ policy (reinforcement learning) #RL
principle of least action
Local $\to$ global :
Dynamic programming
Ex. all the types of simulations.
Evolution and Local-global #Evolution Evolution: What is evolution?
Local global: what is local local?
Sub-representation and Local-Global #sub-representation ?...</p></section><footer class=entry-footer><span title='2023-12-02 00:00:00 +0000 UTC'>December 2, 2023</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Shriman Keshri</footer><a class=entry-link aria-label="post link to Local-global" href=https://shrimansoft.github.io/knowledge-base/pages/local-global/></a></article><article class=post-entry><header class=entry-header><h2>Markove decision process</h2></header><section class=entry-content><p>RL interaction Dynamics RL interaction Dynamics Markov decision process is a mathematical model.
When we fix the policy, the above process becomes automatic. It will just run and run.
Because of a lack of knowledge, we use probability in this. #randomness
The above interaction dynamics can be studied using the MDP. So here, the MDP comes into the picture.
The MDP is how the agent sees his interaction with the world....</p></section><footer class=entry-footer><span title='2023-12-02 00:00:00 +0000 UTC'>December 2, 2023</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Shriman Keshri</footer><a class=entry-link aria-label="post link to Markove decision process" href=https://shrimansoft.github.io/knowledge-base/pages/markove-decision-process/></a></article><article class=post-entry><header class=entry-header><h2>Memory</h2></header><section class=entry-content><p>How do our brain stores the information? it stores its information not in the form it captured it but in the form in which is the most useful for the future.
Data Storage #Memory
I am in search of general Database management system.
This should Coherent with the World view.
It will be just like a world i.e. it will have a input and output.
Do it need a language? Memory is just a communication from past to future....</p></section><footer class=entry-footer><span title='2023-12-02 00:00:00 +0000 UTC'>December 2, 2023</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Shriman Keshri</footer><a class=entry-link aria-label="post link to Memory" href=https://shrimansoft.github.io/knowledge-base/pages/memory/></a></article><article class=post-entry><header class=entry-header><h2>One direction Communication</h2></header><section class=entry-content><p>File storage : communication from past to future. #Memory
In Space: we can do both direction communication .
But in Time we can only do one direction communication.
I was listening to an audiobook (1984 by George Orwell). In that book, The character wanted to write a letter. but he doesn’t have anyone to send this letter,
To whom I am going to write this latter. My Future.
but he wondered how could he communicate with his future....</p></section><footer class=entry-footer><span title='2023-12-02 00:00:00 +0000 UTC'>December 2, 2023</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Shriman Keshri</footer><a class=entry-link aria-label="post link to One direction Communication" href=https://shrimansoft.github.io/knowledge-base/pages/one-direction-communication/></a></article><article class=post-entry><header class=entry-header><h2>persist</h2></header><section class=entry-content><p>Something exist because it exist.
This is very typical kind of reasoning.
Even the evolutionary theory also take that as an axioms.</p></section><footer class=entry-footer><span title='2023-12-02 00:00:00 +0000 UTC'>December 2, 2023</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Shriman Keshri</footer><a class=entry-link aria-label="post link to persist" href=https://shrimansoft.github.io/knowledge-base/pages/persist/></a></article><article class=post-entry><header class=entry-header><h2>randomness</h2></header><section class=entry-content><p>Why do Turing machine with a coin is capable of something more? Why do Nature follow some law ( constraints) and why something are random ( free at least from the Ability of our thought)?
Randomness $\to$ Evolution $\to$ RL I was wondering from where this randomness comes. If we understand from where this randomness comes, we will know the source of the origin of Evolution. We will get the origin of learning in RL....</p></section><footer class=entry-footer><span title='2023-12-02 00:00:00 +0000 UTC'>December 2, 2023</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Shriman Keshri</footer><a class=entry-link aria-label="post link to randomness" href=https://shrimansoft.github.io/knowledge-base/pages/randomness/></a></article><article class=post-entry><header class=entry-header><h2>Reinforcement Learning</h2></header><section class=entry-content><p>Reinforcement learning, on the other hand, is a type of machine learning that involves an agent learning from its environment through trial and error. The agent receives feedback in the form of rewards or punishments for its actions, and over time, it learns to choose actions that maximize its reward. Supervised Learning: Learning with labels defined by human Unsupervised Learning: finding patterns in data. Reinforcement Learning: This is a $4^{rd}$ machine learning paradigm, in which agent tries to maximise its reward signal....</p></section><footer class=entry-footer><span title='2023-12-02 00:00:00 +0000 UTC'>December 2, 2023</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Shriman Keshri</footer><a class=entry-link aria-label="post link to Reinforcement Learning" href=https://shrimansoft.github.io/knowledge-base/pages/reinforcement-learning/></a></article><article class=post-entry><header class=entry-header><h2>The black swan.</h2></header><section class=entry-content><p>Black swan theory - Wikipedia
Theory that unexpected events have major impacts, often rationalized in hindsight.
How can we trust induction hypothesis?
Where is the place for induction hypothesis in the logic?</p></section><footer class=entry-footer><span title='2023-12-02 00:00:00 +0000 UTC'>December 2, 2023</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Shriman Keshri</footer><a class=entry-link aria-label="post link to The black swan." href=https://shrimansoft.github.io/knowledge-base/pages/the-black-swan./></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://shrimansoft.github.io/>« Prev Page</a>
<a class=next href=https://shrimansoft.github.io/page/3/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://shrimansoft.github.io/knowledge-base/>Shriman Keshri</a></span><br><span>Powered by
<a href=https://github.com/sawhney17/logseq-schrodinger rel=noopener target=_blank>Logseq Schrödinger</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>