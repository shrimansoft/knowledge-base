[{"content":"Hello, everyone. I recently gave a talk on neural networks at the NISER Coding Club. The address was intended for a general audience. So, we have yet to use any technical jargon. In this post, I will convey the same here, But before I begin I like to point out that this bog has some exercise that is degined to make you absrobe the matarial for its fullest. So, if you are reading to Get the Real\nWe begin with the definition of the RuLU function.\nReLU $$\\sigma(x) = \\max(0,x)$$ Examples of ReLU Let\u0026rsquo;s see some of the examples variation of this function ReLU. To get the deeper undrrstading of this I like you to pratice this simple exercise.\n$$\\sigma(x+1)$$\n+ $$\\sigma(x-1)$$\n+ $$\\sigma(x-1) +1$$\n+ $$\\sigma(-x)$$\n+ $$\\sigma(-x-1)$$ + Some More Examples $$\\sigma(x)- \\sigma(x-1)$$ + $$\\sigma(x-0) -\\sigma(x-1) + \\sigma(x-2) - \\sigma(x-3)$$ + $$\\sigma(x-0) -\\sigma(x-1) + \\sigma(x-2) - \\sigma(x-3) -\\sigma(x-4) +\\sigma(x-6)$$ Some Exercise These Exercise will me the above Idea concrete in your mind and you will have no problem understanding the next part of the blog.\nPlot the graph of the following function $$-\\sigma(x-1)$$ Plot the graph of the following function $$\\sigma(x-2)$$ Plot the graph of the following function $$-\\sigma(x-3)$$ If you can plot the above try poling the combination of above two: $$\\sigma(x-2) -\\sigma(x-3)$$ Very good.\nNeural network. https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/500px-Colored_neural_network.svg.png\nThe above picture I took from the Wikipedia page. If you see here you will get lot of thing about it\u0026rsquo;s aplication, model user and a lot, but Right now we will look at a perticuler exmaple of it and see what its all about. Lets begin.\nThis is how a simple nuron looks, if we write it matamaticaly its a function $y:\\mathbb{R}\\to\\mathbb{R}$.\n$$y(x) = \\sigma(Wx + B)$$\nwhere $\\sigma$ is ReLU function that we looked at the above.\nSo $\\sigma(x) will look like:\nVery good. its plot will be same as $\\sigma(x)$.\nExamples Now we will repeat the above example and see how thy look as neural network.\n$$\\sigma(x+1)$$\n+ + $$\\sigma(x-1)$$\n+ $$\\sigma(x-1) +1$$\n+ $$\\sigma(-x)$$\n+ $$\\sigma(-x-1)$$ + Some More Examples $$\\sigma(x)- \\sigma(x-1)$$ + $$\\sigma(x-0) -\\sigma(x-1) + \\sigma(x-2) - \\sigma(x-3)$$ + $$\\sigma(x-0) -\\sigma(x-1) + \\sigma(x-2) - \\sigma(x-3) -\\sigma(x-4) +\\sigma(x-6)$$ Some Exercise These Exercise will me the above Idea concrete in your mind and you will have no problem understanding the next part of the blog.\nPlot the graph of the following function $$-\\sigma(x-1)$$ Plot the graph of the following function $$\\sigma(x-2)$$ Plot the graph of the following function $$-\\sigma(x-3)$$ If you can plot the above try poling the combination of above two: $$\\sigma(x-2) -\\sigma(x-3)$$ Very good.\n","permalink":"https://shrimansoft.github.io/knowledge-base/pages/why-neural-network/","summary":"Hello, everyone. I recently gave a talk on neural networks at the NISER Coding Club. The address was intended for a general audience. So, we have yet to use any technical jargon. In this post, I will convey the same here, But before I begin I like to point out that this bog has some exercise that is degined to make you absrobe the matarial for its fullest. So, if you are reading to Get the Real","title":"Why Neural network"},{"content":"These are the list of big realisations I have experienced. Idea of separation is an illusion.\nTime is an illusion. ( there is no time there is only Unfolding )\nWe are not an exception to this nature. We are an example.\nThe force of feeling and how we can avoid this by practicing Vespasian.\n( not yet realized ) The world is dynamic. ( Becoming otherwise)\n( not yet realized ) Why do we exist? Who am I? From where are all these things coming into existence? Why does this something exist? Why do I exist?\nCircle of time\nI don\u0026rsquo;t know how to name it yet\nBut this idea is that we have some freedom to act and some constraints. Similarly, I think everything in this universe is like that. ","permalink":"https://shrimansoft.github.io/knowledge-base/pages/big-realizations/","summary":"These are the list of big realisations I have experienced. Idea of separation is an illusion.\nTime is an illusion. ( there is no time there is only Unfolding )\nWe are not an exception to this nature. We are an example.\nThe force of feeling and how we can avoid this by practicing Vespasian.\n( not yet realized ) The world is dynamic. ( Becoming otherwise)\n( not yet realized ) Why do we exist?","title":"Big realizations"},{"content":" ","permalink":"https://shrimansoft.github.io/knowledge-base/pages/circle-of-time/","summary":" ","title":"Circle of time"},{"content":" What do we mean my generalization?\nBy the Process and Reality \u0026ldquo;we are no exception to this nature we are example of it\u0026rdquo;. Taking this Idea we can say that everything is like us has some level of active participation in the nature and during this interaction these things are evolving too.\nTo make this some what abstract Idea that every thing are like us evolving. I like to generalise this Idea that there is an agent rather every thing is an agent.\nSo for us( an agent) what other agents are look like? what is in the eye of a agent other agents are. they are either world in which we live in or the tools we use.\nso lets begin our journey with tools.\nTo generalise the RL structure, We generalise how we see the Agent World Interaction. such that every thing is an agent ( i.e. some thing that can perceive and has ability to evolve).\nSuch that it includes the concept of tools.\nWe can see how this will look in the Agent World Interaction. But our challenge is to make it mathematically precise, i.e. how will this come in when we model the interaction dynamics using the MDP? So after we try to model this general structure like Markove decision process, let us call this General_MDP.\nSo right now, the big challenges I have to make this General_MDP and how can we introduce Modularity in this.\nBefore I start and wonder about the above challenges. Let\u0026rsquo;s see how the State and Observation are in the view of MDP.\n+ How to make this magic box#wondering + **Observation** is in the flow, i.e. continuous. #continuous vs quantised State is stable, i.e. quantised. Action is in the flow, i.e. continuous. Decision is quantised.\n","permalink":"https://shrimansoft.github.io/knowledge-base/pages/generalisation-of-reinforcement-learning/","summary":"What do we mean my generalization?\nBy the Process and Reality \u0026ldquo;we are no exception to this nature we are example of it\u0026rdquo;. Taking this Idea we can say that everything is like us has some level of active participation in the nature and during this interaction these things are evolving too.\nTo make this some what abstract Idea that every thing are like us evolving. I like to generalise this Idea that there is an agent rather every thing is an agent.","title":"Generalisation of reinforcement learning"},{"content":"Reinforcement Learning\nConsciousness\nModularity\nCausal inference\nEvolution\nAbility to use tool\nLanguage ( giving identity to our feelings)\nrandomness\nsub-representation\nReprasentation\nlearning\nImages of Important Ideas tools\nRL\nrandomness\nExact sequence\nattention\naction = observation\nCircle of time.\nWorld view\nDifferent feeling\nRandomness/ Predictability.\nTime\nSpace\nSeparation/ Identity\nIntelligence/ consciousness.\nDrive ( unmoved mover)\nCreativity.\nFree will\nHow log is this present?\nHow past -\u0026gt; future?\nwhere is action action min comes from?\nwhere is love\nAttention??\n","permalink":"https://shrimansoft.github.io/knowledge-base/pages/important-ideas/","summary":"Reinforcement Learning\nConsciousness\nModularity\nCausal inference\nEvolution\nAbility to use tool\nLanguage ( giving identity to our feelings)\nrandomness\nsub-representation\nReprasentation\nlearning\nImages of Important Ideas tools\nRL\nrandomness\nExact sequence\nattention\naction = observation\nCircle of time.\nWorld view\nDifferent feeling\nRandomness/ Predictability.\nTime\nSpace\nSeparation/ Identity\nIntelligence/ consciousness.\nDrive ( unmoved mover)\nCreativity.\nFree will\nHow log is this present?\nHow past -\u0026gt; future?\nwhere is action action min comes from?","title":"Important ideas"},{"content":"id:: 6480345f-4734-4296-ab89-5203b50f3c33 RL interaction Dynamics Markove decision process is a mathematical model.\nWhen we fix the policy, the above process becomes automatic. It will just run and run.\nBecause of a lack of knowledge, we use probability in this. #randomness\nThe above interaction dynamics can be studied using the MDP. So here the MDP comes in picture.\nThe MDP is how the agent sees his interaction with the world.\nLet me elaborate on this and give a picture of where this idea will fit in the scheme of World view. So, we start our story with two players one is our robot $R$ and is the enlivenment where the robot acts say $E$. Now there is up to how is thinking about all these interactions. Here the person who is thinking about the interaction says $Thinker$.\nThe question is, where is this MDP? The MDP is modelled by the $Thinker$ and placed in side the code/brain of $R$. What this MDP is representing. Its representing the dynamics of the interaction between $R$ and $E$. alring.\nSo, what we get from this? that there is complete interaction dynamics which is going in side the head of $R$ which is some partial representaiton of the real dynamics which is going to happen on real.\nvery good. now we can see there is two interaction flow one is on real-world where real robot build of moters, battery and chipes is action on the environment. and the other one which is action in the head of the $R$.\nbut the point the concern me is this. The model of the is not build by the $R$ or some code in side the $R$. its someting we crated and placed in the $R$ . But in case of us we human we found the interaction dynamics by our own.\nThe question this leades me to are: How we know that we are not the part of this enviroment? how do we com and get awear the table is not the same as pen. how do we know how to interacte with them and how the concept of tool which say make us not only awear of how we interact in this world. but also. how on opject in the world interact with the other object in the world.\nRemark: at the above line where I write \u0026ldquo;object\u0026rdquo; is the world in the World view.\nLet me elaborate on this and give a picture of where this idea will fit in the scheme of World view. So, we start our story with two players one is our robot $R$ and is the enlivenment where the robot acts say $E$. Now there is up to how is thinking about all these interactions. Here the person who is thinking about the interaction says $Thinker$.\nThe question is, where is this MDP? The MDP is modelled by the $Thinker$ and placed in side the code/brain of $R$. What this MDP is representing. Its representing the dynamics of the interaction between $R$ and $E$. alring.\nSo, what we get from this? that there is complete interaction dynamics which is going in side the head of $R$ which is some partial representaiton of the real dynamics which is going to happen on real.\nvery good. now we can see there is two interaction flow one is on real-world where real robot build of motors, battery and chips is action on the environment. and the other one which is action in the head of the $R$.\nbut the point the concern for me is this. The model of this is not build by the $R$ or some code in side the $R$. its something we crated and placed in the $R$ . But in case of us we human we found the interaction dynamics by our own.\nThe question this leads me to are: How we know that we are not the part of this environment? how do we come and get aware that the table is not the same as pen. how do we know interaction with them and how the concept of tool which say make us not only aware of how we interact in this world. but also. how on object in the world interact with the other object in the world.\nRemark: at the above line where I write \u0026ldquo;object\u0026rdquo; is the world in the World view.\nBy looking the the above challenge. I am going to propose an experiment challenge: The Challenge: given a $agent$ \u0026lt;-\u0026gt; $world$ interaction. where the world is consist of two worlds say $world$ := $world 1$ \u0026lt;-\u0026gt; $world 2$. the challenge the agent has is to find the MDP which represent the $agent$ \u0026lt;-\u0026gt; $world$ to The MDP which is representing the $agent$ \u0026lt;-\u0026gt; $world 1$ \u0026lt;-\u0026gt; $world 2$.\nOK the next problem is how can we write the MDP with three interacting or three world. where each of them.\nBy looking the the above chalange. I am going to propose an experiment chalange: The Chalange: given a $agent$ \u0026lt;-\u0026gt; $world$ interaction. where the world is consit of two worlds say $world$ := $world1$ \u0026lt;-\u0026gt; $world2$. the chanlage the agent has is he need to find the MDP which is representitng the $agent$ \u0026lt;-\u0026gt; $world$ to The MDP which is representing the $agent$ \u0026lt;-\u0026gt; $world1$ \u0026lt;-\u0026gt; $world2$.\nOK the next problam is how can we write the MDP with three ingridinan or three world. where each of them.\nTriangular MDP This MPP is the generalisation of the interaction with the world that Is and built. When you think about a bike, you don\u0026rsquo;t see all the nuts and bolts. You see how it operates and how its state changes when you perform some action. the Idea of a bike is the MDP of the Bike in our head.\nThis is cool. When I say I know something i.e. I know the behaviour of that thing and how it changes based on my action. I know the dynamic rules of that person or thing. #knowing\nRemark: Most real scenarios are unlikely to be Markov.\nQuestion: How are we dealing with this? this question has two parts. one, what are the technic we have in computer science to deal with this. another one is how we humans are dealing with this.\nAnswer: I don\u0026rsquo;t this will have a clear and clean answer. but let me mention some points.\nMemory of the past states that we use to handle this. we can have Indexes That depends on the past state. Through this we can gather some particular information for the past states. There is a quote that I read in the course of Second Brain that \u0026ldquo;we humans are good at recognising then recalling\u0026rdquo;. So, what this is saying this how we retreat information from our Memory. #Memory ","permalink":"https://shrimansoft.github.io/knowledge-base/pages/markove-decision-process/","summary":"id:: 6480345f-4734-4296-ab89-5203b50f3c33 RL interaction Dynamics Markove decision process is a mathematical model.\nWhen we fix the policy, the above process becomes automatic. It will just run and run.\nBecause of a lack of knowledge, we use probability in this. #randomness\nThe above interaction dynamics can be studied using the MDP. So here the MDP comes in picture.\nThe MDP is how the agent sees his interaction with the world.\nLet me elaborate on this and give a picture of where this idea will fit in the scheme of World view.","title":"Markove decision process"},{"content":"Thought The complexity of the system increases when we go from atoms to Organism.\nWe can understand And Realise Some of the above structures of the system to predict what will going happen to the system. #sub-representation #randomness\nThat is good, but why is there modularity in nature itself?\nwhat is the reason? why does one world want to control another world why why?\nWe can say something exists that\u0026rsquo;s why it exists.\nTo exist, the world wants control over another world !!\nTo exist, do we want control over the other world?\nwhy does the world need control over other world to exist?\nis there something more fundamental we need from another world? REMARK: abstract things don\u0026rsquo;t exist on their own. Some abstract concepts exist with time. so, this abstract idea needs control over another world to get something.\nREMARK: but thinking that this is our word, and there is some other world that is the choice we have in our world. So that everything may be one.\nThere is no separation at all\nFUCK\nwhere is this going? Is this entire game just the fuck of mind to make us exist and fuck.\nThis thought may not take us anywhere; it will just give us the chance to fuck. But there is no fundamental truth to explore at all\nModularity forced by the User. I read some papers on modularity. Then I realised the following things: cite:: cluneEvolutionaryOriginsModularity2013\nWe divide a complex system into small modules to understand it better.\nThere is no reason why a complex system to be modular on its own. We usually make it modular so that we can understand it better.\nEmergence of simplicity. todo:: hello\nWhen a learning system uses other learning systems to solve some task, if the second learning system is too complicated for the first one to understand, Then the first one will not use it. But if a second learning system is easy to understand, the first one will use it. #World view\nIn other words, we can see that the higher level of learning system forces the lower levels of learning systems to be modular in a hierarchical system. (Maybe it\u0026rsquo;s possible on a non-hierarchical learning system structure).\nRelation of modularity from continuty An agent can have a modular solution if the task is modular.\nWe represent the task through the reward function.\nIt means we can break the reward function into a sub-reward function.\nSpliting a function and modularity. Let us have a function.\n$$ f : \\mathbb{R}^n \\rightarrow R^m $$\nwe can write it as $$ f_i : R^n \\rightarrow R \\textbf{ where } i \\in {1,..,m} $$\nIf you are trying to tarin a function approximator to clone the function $f$. There are two possible causes:\nThere is a picture, and a good explanation of this is given in a photo. Add the photo here Case1: $\\forall i$, $f_i$ is independent, then whether we train this function independently or together doesn\u0026rsquo;t matter.\nCase2: if the parameters depend on each other, we have to train them together to get more efficiency.\nExperimental verification of the above hypothesis: generate the data from a well-defined function $F:\\mathbb{R}^m \\rightarrow \\mathbb{R}^n$. Then we train a neural network to mimic it. Yes, we can do that, but we will first train it to predict the $F_i$ individually and computer it by teaching the hole function.\nWe will make some modular structures in the $F$ and see the above comparation.\nWhat is that modular structure\nModularity and evolvability “A major contributor to evolvability is the fact that many biological entities are modular” 1\n“Modularly varying goals seem to push populations away from local fitness maxima and guide them toward evolvable and modular solutions.”1\nJ. Clune, J.-B. Mouret, and H. Lipson, “The evolutionary origins of modularity,” Proceedings of the Royal Society B: Biological Sciences, vol. 280, no. 1755, p. 20122863, Mar. 2013, doi: 10/gfzdrv.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://shrimansoft.github.io/knowledge-base/pages/modularity/","summary":"Thought The complexity of the system increases when we go from atoms to Organism.\nWe can understand And Realise Some of the above structures of the system to predict what will going happen to the system. #sub-representation #randomness\nThat is good, but why is there modularity in nature itself?\nwhat is the reason? why does one world want to control another world why why?\nWe can say something exists that\u0026rsquo;s why it exists.","title":"Modularity"},{"content":"Reinforcement learning, on the other hand, is a type of machine learning that involves an agent learning from its environment through trial and error. The agent receives feedback in the form of rewards or punishments for its actions, and over time, it learns to choose actions that maximize its reward. Supervised Learning: Learning with labels defined by human Unsupervised Learning: finding patterns in data. Reinforcement Learning: This is a $4^{rd}$ machine learning paradigm, in which agent tries to maximise its reward signal. through agent \u0026lt;-\u0026gt; world interaction.\nImportant terms in RL.\nPolicy:\nReward signal\nValue function\nModel of environment\nMarkove decision process\n","permalink":"https://shrimansoft.github.io/knowledge-base/pages/reinforcement-learning/","summary":"Reinforcement learning, on the other hand, is a type of machine learning that involves an agent learning from its environment through trial and error. The agent receives feedback in the form of rewards or punishments for its actions, and over time, it learns to choose actions that maximize its reward. Supervised Learning: Learning with labels defined by human Unsupervised Learning: finding patterns in data. Reinforcement Learning: This is a $4^{rd}$ machine learning paradigm, in which agent tries to maximise its reward signal.","title":"Reinforcement Learning"},{"content":"What I mean when I say unfolding. It\u0026rsquo;s like something was folded before, and now we are unfolding it. So, what do we mean? I like to talk about this thing with examples of this unfolding.\nExample 1 DNA $\\to$ organism.\nExample 2 Everything in this nature is unfolding. Time is it self a manifestation of this unfolding.\nExample 3 future $\\to$ present $\\to$ past ( this is coming from Process and Reality ) #Circle of time\nI think above me have given some nice examples of what is unfolding. but the important question here is that what is the inverse of this pronomina?\nI am not saying that Organism will become DNA. or the Past will become future. What I am saying is this how do DNA evolves? how do the future get manifested in our mind before it unfolded through action?\nIn neural network we use back propagation. which is similar to the reviser of unfolding.\nOpen question: What is the inverse of the concept of unfolding? How do we understand the process by which the future becomes manifested in our minds before it has been acted upon?\n","permalink":"https://shrimansoft.github.io/knowledge-base/pages/unfolding/","summary":"What I mean when I say unfolding. It\u0026rsquo;s like something was folded before, and now we are unfolding it. So, what do we mean? I like to talk about this thing with examples of this unfolding.\nExample 1 DNA $\\to$ organism.\nExample 2 Everything in this nature is unfolding. Time is it self a manifestation of this unfolding.\nExample 3 future $\\to$ present $\\to$ past ( this is coming from Process and Reality ) #Circle of time","title":"Unfolding"},{"content":"Before I talk about the Triangular MDP, let me first discuss the idea of separation. Why am I talking about this? Because there are two challenges we have with Triangular MDP. One is how it works if it is already there, and the other is how it can come into being from thin air.\nI will try to answer the first one on the page of Triangular MDP, but to address the second question, we need to look at how humans get the idea of separation.\nWhat I experience is that the thing we see separately is only based on the fact that stuff near can affect each other, and things that are fare away can\u0026rsquo;t affect each other. The localization of causation is the root of our idea of separation. We say I am acting on $A$ and not in $B$ because they are separated by space or time. Say I acted on this today, and I acted on that tomorrow. Somehow all these things I think are head to answer are coming and connecting each other and I don\u0026rsquo;t know form where should I start.\nI remember in a conversation with Ashoke Sen., I told him that in quantum entanglement, things are connected through distance, which looks counterintutu when we look at it through the lens of the separation-based spatial(\u0026ldquo;related to space\u0026rdquo;). may be the idea of separation we are doing is not right on the first place. Maybe the thing we are thinking is not separate. We can say that because we have to deal with the uncertainty of the system. We don\u0026rsquo;t know how it\u0026rsquo;s coming into the picture. With this, we opened the initial new page of mystery that physicists have been working on for a long time: the \u0026ldquo;Who do entanglement works\u0026rdquo;. Science is not everything, but this is what we have right now. How much do I say I am not a scientist anymore? I will be working under it becouse I don\u0026rsquo;t have anything more than this (\u0026ldquo;scientific method of investigation\u0026rdquo;).\nRemark One more way to see this idea of separation is when a world realizes another world for achieving some control over it. By the constraints of randomness, we achieve sub-representation. During these subrepresations, the set of things mapped to one thing are called \u0026ldquo;things,\u0026rdquo; which is the source of separation.\n","permalink":"https://shrimansoft.github.io/knowledge-base/pages/idea-of-separation/","summary":"Before I talk about the Triangular MDP, let me first discuss the idea of separation. Why am I talking about this? Because there are two challenges we have with Triangular MDP. One is how it works if it is already there, and the other is how it can come into being from thin air.\nI will try to answer the first one on the page of Triangular MDP, but to address the second question, we need to look at how humans get the idea of separation.","title":"Idea of separation"},{"content":"","permalink":"https://shrimansoft.github.io/knowledge-base/pages/jul-21st-2023/","summary":"","title":"Jul 21st, 2023"}]