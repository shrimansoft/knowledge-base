---
status:
- unfinished
icon: ðŸ¤–
title: Generalisation of reinforcement learning
tags:
categories:
date: 2023-12-02
lastMod: 2023-12-04
---
> What do we mean my generalization?

By the Process and Reality "*we are no exception to this nature we are example of it*". Taking this Idea we can say that everything is like us has some level of active participation in the nature and during this interaction these things are evolving too. 

To make this some what abstract Idea that every thing are like us evolving. I like to generalise this Idea that there is an agent rather every thing is an agent. 

So for us( an agent) what other agents are look like? what is in the eye of a agent other agents are. they are either world in which we live in or the tools we use.

so lets begin our journey with tools.

To generalise the RL structure, We generalise how we see the **Agent World Interaction**. such that every thing is an agent ( i.e. some thing that can perceive and has ability to evolve).

Such that it includes the concept of tools.

We can see how this will look in the Agent World Interaction. But our challenge is to make it mathematically precise, i.e. how will this come in when we model the interaction dynamics using the MDP?
So after we try to model this general structure like [Markove decision process]({{< ref "/pages/Markove decision process" >}}), let us call this General_MDP.

So right now, the {{< logseq/mark >}}big challenges{{< / logseq/mark >}} I have to make this General_MDP and how can we introduce [Modularity]({{< ref "/pages/Modularity" >}}) in this.

Before I start and wonder about the above challenges. Let's see how the {{< logseq/mark >}}State and Observation{{< / logseq/mark >}} are in the view of MDP.

![image.png](/assets/image_1679671977218_0.png)

    + How to make this magic box#wondering

    + **Observation** is in the flow, i.e. continuous. #continuous vs quantised 
**State** is stable, i.e. quantised. 
**Action** is in the flow, i.e. continuous. 
**Decision** is quantised.
